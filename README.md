> **Notice:**
The latest, actively developed versions of my main bioinformatics projects are on their respective `2.0` branches:
- [biolm_utils: biolm-2.0 branch](https://github.com/dieterich-lab/biolm_utils/tree/biolm-2.0)
- [rna_protein_xlnet: xlnet-2.0 branch](https://github.com/dieterich-lab/rna_protein_xlnet/tree/xlnet-2.0)
- [rna_saluki_cnn: saluki-2.0 branch](https://github.com/dieterich-lab/rna_saluki_cnn/tree/saluki-2.0)

The `main` branches are legacy. Please check out the `2.0` branches for the newest features, code, and documentation.

---

### Hi there, I'm Philipp üëã

I'm an AI Scientist specializing in Generative AI and Natural Language Processing. My passion is building intelligent systems that can decipher complex, human-generated data ‚Äì from ancient languages to modern clinical records.

Below is a selection of key projects I've led or significantly contributed to during my time at the Klaus-Tschira-Institute (Dieterich Lab).

---

### üöÄ Key Projects & Contributions

#### 1. Architect of `biolm_utils`: A Deep Learning Framework for Bioinformatics
*   **Project:** [`dieterich-lab/biolm_utils`](https://github.com/dieterich-lab/biolm_utils)
*   **My Role:** **Lead Architect & Developer.** This framework is the heart of our bioinformatics research. I designed and built it from the ground up to be a modular and extensible engine for deep learning on biological sequences. It handles the entire ML lifecycle, including data processing, model training, prediction, and Explainable AI (XAI) integration.

#### 2. Application: `rna_protein_xlnet` (Transformer-based Modeling)
*   **Project:** [`dieterich-lab/rna_protein_xlnet`](https://github.com/dieterich-lab/rna_protein_xlnet)
*   **My Role:** **Lead Developer.** This project is a key application built on top of the `biolm_utils` framework. I demonstrated the framework's power by integrating a state-of-the-art Transformer model (XLNet) as a plugin to accurately predict RNA and protein half-lives from sequence data.

#### 3. Application: `rna_saluki_cnn` (CNN-based Modeling)
*   **Project:** [`dieterich-lab/rna_saluki_cnn`](https://github.com/dieterich-lab/rna_saluki_cnn)
*   **My Role:** **Core Contributor.** In this project, we showcased the framework's flexibility by implementing a custom, lightweight CNN architecture (Saluki) as another model plugin, applying it to the same sequence-to-outcome task.
*   **Citation:** Agarwal, V., & Kelley, D. (2022). The genetic and biochemical determinants of mRNA degradation rates in mammals. bioRxiv.

#### 4. LLM Relations: Knowledge Graph Generation from Scientific Text
*   **Project:** [`dieterich-lab/LLM_Relations`](https://github.com/dieterich-lab/LLM_Relations)
*   **My Role:** **Lead Developer & Architect.** Separate from the bioinformatics framework, I designed and implemented this system for using Large Language Models (Mistral, Llama) to extract molecular interaction data and construct a biological relation graph.
*   *Note: My specific contribution can be viewed in the project's [subdirectories](https://github.com/dieterich-lab/LLM_Relations/tree/main/llm_extractions).*

#### 5. BertGCN: Graph Neural Networks for Clinical Text Classification
*   **Project:** [`dieterich-lab/BertGCN`](https://github.com/dieterich-lab/BertGCN)
*   **My Role:** **Lead Developer.** This is a re-implementation of the BertGCN model [Lin et al., 2021], currently adapted for clinical text classification tasks. We combine BERT embeddings with Graph Convolutional Networks to improve classification performance on medical indication data, with plans to extend the framework for broader biomedical applications.
*   **Citation:** Lin, Y., Meng, Y., Sun, X., Han, Q., Kuang, K., Li, J., & Wu, F. (2021). BertGCN: Transductive Text Classification by Combining GCN and BERT. arXiv preprint arXiv:2105.05727.
*   **Note:** This implementation uses confidential clinical data. No training data or trained models are publicly shared to maintain patient privacy and data security.

---

### üåç Community & Open Source Contributions

#### Ancient Egyptian Translation Dataset
*   **Hugging Face Link:** [`phiwi/bbaw_egyptian`](https://huggingface.co/datasets/phiwi/bbaw_egyptian)
*   **Context:** This project connects my unique background in both Egyptology and Computational Linguistics. I curated, processed, and uploaded this dataset to the Hugging Face Hub to make it accessible for the community, enabling new research in low-resource machine translation. This work is directly related to my IWSLT 2019 publication on translating ancient texts with Transformer models.

---

### üìö Lectures & Teaching

#### Graph Neural Networks in Modern Medicine
*   **Date:** November 13, 2025
*   **Audience:** Master's students in Medical Informatics
*   **Duration:** 90 minutes
*   **Topic:** Introduction to Graph Neural Networks, exploring their applications from molecular interactions to patient outcomes in biomedical research.
*   **Slides:** [View Presentation](https://phiwi.github.io/graphnn_lecture/)

---

### üõ†Ô∏è My Tech Stack

*   **Languages:** Python, Bash, Cypher, Java
*   **AI/ML:** PyTorch, Huggingface, Langchain, LlamaIndex, Scikit-Learn, Spacy
*   **Infrastructure & Data:** Docker, Git, HPC/Slurm, Neo4j, FAISS, MongoDB

---

[<img src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/linkedin.svg" alt="'linkedin'" width="40"/>](https://www.linkedin.com/in/philipp-wiesenb/)   [<img src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/googlescholar.svg" alt="google scholar" width="40"/>](https://scholar.google.de/citations?user=zdNEDqgAAAAJ&hl=de)¬†   [<img src="https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo.svg" alt="hugging face" width="40"/>](https://huggingface.co/phiwi)
